{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tweets = pd.read_csv('tweets_new_train.csv')\n",
    "\n",
    "tweets.dtypes.index\n",
    "tweets = tweets[['text', 'tweet_class', 'query']]\n",
    "\n",
    "smallest_len = min(len(tweets[tweets['tweet_class'] == 1]),\n",
    "                len( tweets[tweets['tweet_class'] == -1]),\n",
    "                len( tweets[tweets['tweet_class'] == 0]),\n",
    "               len( tweets[tweets['tweet_class'] == 2]),\n",
    "                  )\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data = data.append(tweets[tweets['tweet_class']==-1])\n",
    "data = data.append(tweets[tweets['tweet_class']==0][:smallest_len])\n",
    "data = data.append(tweets[tweets['tweet_class']==1][:smallest_len])\n",
    "data = data.append(tweets[tweets['tweet_class']==2][:smallest_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4416, 2547) (4416,)\n",
      "0       <SHOW_NAME> s arkangel tech so i can block out...\n",
      "1       i would love to im in <SHOW_NAME> ga where do ...\n",
      "2       just seen some more gameplay for detroit becom...\n",
      "3       i liked a <HANDLE> video <URL> fear <SHOW_NAME...\n",
      "4                           then u dey watch <SHOW_NAME> \n",
      "5       ive just watched episode s01e07 of <SHOW_NAME>...\n",
      "6       <SHOW_NAME> with charlie sheen was a masterpie...\n",
      "7                                             <SHOW_NAME>\n",
      "8                        binging <SHOW_NAME>  2 thumbs up\n",
      "9       it looks like youre just outside of our delive...\n",
      "10      second season of <SHOW_NAME> got me all fucked up\n",
      "11                <SHOW_NAME>  pic.twitter.com/fvqv4azjfw\n",
      "12      why avengers infinity war will feel a little l...\n",
      "13      <SHOW_NAME> season 8 news jon snow dealt bruta...\n",
      "14      hey <HANDLE> & <HANDLE> my tribute art to 8:09...\n",
      "15      ive just watched episode s14e15 of <SHOW_NAME>...\n",
      "16      so thank you <SHOW_NAME>  for reminding me i‚Äôm...\n",
      "17           <HANDLE> is my family my comfort and my home\n",
      "18      finished season 1 of <SHOW_NAME>  not a fan i ...\n",
      "19                            starting with <SHOW_NAME> üëè\n",
      "20      boyfriendoftheyear surprised his girlfriend wi...\n",
      "21      i added a video to a <HANDLE> playlist <URL> i...\n",
      "22      people on my tl talking about <SHOW_NAME>  i f...\n",
      "23                                            <SHOW_NAME>\n",
      "24       <SHOW_NAME> season 07 pic.twitter.com/as4tjtjrjd\n",
      "25      marquei como visto <SHOW_NAME>  1x7  a brisket...\n",
      "26      your sliceline order is confirmed start saving...\n",
      "27      ive just watched episode s14e14 of <SHOW_NAME>...\n",
      "28      ive just watched episode s05e12 <SHOW_NAME> fu...\n",
      "29           this episode of <SHOW_NAME> has me hollering\n",
      "                              ...                        \n",
      "4386                         the guy from big bang theory\n",
      "4387                   since <SHOW_NAME> is already taken\n",
      "4388      <SHOW_NAME> was a romp fun for the whole family\n",
      "4389    i voted for team <SHOW_NAME> on <HANDLE> is th...\n",
      "4390    emmy award consideration for <SHOW_NAME> @ jer...\n",
      "4391    <SHOW_NAME>  t08e11  dead or alive or pic.twit...\n",
      "4392     just posted a photo @ <SHOW_NAME>  georgia <URL>\n",
      "4393    tsw rim casino 18x9.5 5x4.5 offset 40 gloss bl...\n",
      "4394                             i second <SHOW_NAME> too\n",
      "4395    i just think i could coach this team to drop 4...\n",
      "4396    ive just watched episode s02e04 of <SHOW_NAME>...\n",
      "4397                               neither is <SHOW_NAME>\n",
      "4398    watched an episode of <SHOW_NAME>  awful pic.t...\n",
      "4399    this man on <SHOW_NAME> smacking on this gum r...\n",
      "4400    gostei de um v√≠deo <HANDLE> <URL> ‚Ä¶ react to m...\n",
      "4401    were hiring read about our latest job opening ...\n",
      "4402    yay almost done with markings i guess going to...\n",
      "4403    the elmhurst mens lacrosse team overwhelmed wh...\n",
      "4404    <SHOW_NAME> will come next year / they should ...\n",
      "4405                                          <SHOW_NAME>\n",
      "4406    if you combined how i met your mother the big ...\n",
      "4407                                          <SHOW_NAME>\n",
      "4408    fast cheap and hot  your sliceline order is co...\n",
      "4409    melhores s√©ries ‚Äî the <SHOW_NAME>  pretty litt...\n",
      "4410    quick ending <SHOW_NAME> ready player one swee...\n",
      "4411    ok so lema√Ætre was the first to propose <SHOW_...\n",
      "4412         hey have you by any chance seen <SHOW_NAME> \n",
      "4413               <SHOW_NAME> pic.twitter.com/4chooycwwg\n",
      "4414    botva17 best of tv awards 2017 best new televi...\n",
      "4415    vient de regarder a brisket voodoo and cannonb...\n",
      "Name: text, Length: 4416, dtype: object\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5, \n",
    "     max_df=0.95, \n",
    "     sublinear_tf = True,\n",
    "     use_idf = True,\n",
    "     ngram_range=(1, 2),\n",
    "    )\n",
    "\n",
    "classifier = LinearSVC(C=0.1)\n",
    "Xs = vectorizer.fit_transform(tweets['text'])\n",
    "\n",
    "print(Xs.shape, tweets['tweet_class'].shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xs, tweets['tweet_class'], test_size = 0.33, random_state = 42)\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# score = cross_val_score(classifier, Xs, tweets['tweet_class'], cv=2, n_jobs=-1)\n",
    "\n",
    "# print(sum(score) / len(score))\n",
    "\n",
    "print(tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7057613168724279"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(vectorizer.transform(['cersei lannister is the worst character on <SHOW_NAME>  pic.twitter.com/ibj74x3xfq']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
