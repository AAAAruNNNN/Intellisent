{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('intellisent/tweets_new.csv')\n",
    "\n",
    "tweets.dtypes.index\n",
    "tweets = tweets[['text', 'tweet_class']]\n",
    "\n",
    "smallest_len = min(len(tweets[tweets['tweet_class'] == 1]),\n",
    "                len( tweets[tweets['tweet_class'] == -1]),\n",
    "                len( tweets[tweets['tweet_class'] == 0]),\n",
    "               len( tweets[tweets['tweet_class'] == 2]),\n",
    "                  )\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data = data.append(tweets[tweets['tweet_class']==-1])\n",
    "data = data.append(tweets[tweets['tweet_class']==0][:smallest_len])\n",
    "data = data.append(tweets[tweets['tweet_class']==1][:smallest_len])\n",
    "data = data.append(tweets[tweets['tweet_class']==2][:smallest_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    remove_url = re.sub(r'http\\S+', '', x)\n",
    "    remove_replies = re.sub(r'@\\S+', '', remove_url)\n",
    "    return remove_replies\n",
    "    \n",
    "data['cleaned'] = data['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['cleaned'].values)\n",
    "X = tokenizer.texts_to_sequences(data['cleaned'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(9000 + 1, 200, input_length = X.shape[1]))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.tweet_class == -1, 'tweet_class'] = 3\n",
    "\n",
    "Y = data['tweet_class']\n",
    "\n",
    "transformed_Y = to_categorical(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,transformed_Y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 301 samples, validate on 34 samples\n",
      "Epoch 1/7\n",
      "301/301 [==============================] - 15s 50ms/step - loss: 1.4243 - acc: 0.2359 - val_loss: 1.3771 - val_acc: 0.2647\n",
      "Epoch 2/7\n",
      "301/301 [==============================] - 15s 49ms/step - loss: 1.3195 - acc: 0.4452 - val_loss: 1.2558 - val_acc: 0.4412\n",
      "Epoch 3/7\n",
      "301/301 [==============================] - 15s 50ms/step - loss: 0.9740 - acc: 0.6645 - val_loss: 1.2437 - val_acc: 0.5000\n",
      "Epoch 4/7\n",
      "301/301 [==============================] - 15s 51ms/step - loss: 0.5477 - acc: 0.8206 - val_loss: 1.3914 - val_acc: 0.5294\n",
      "Epoch 5/7\n",
      "301/301 [==============================] - 15s 51ms/step - loss: 0.2946 - acc: 0.9302 - val_loss: 1.4793 - val_acc: 0.5294\n",
      "Epoch 6/7\n",
      "301/301 [==============================] - 16s 52ms/step - loss: 0.1252 - acc: 0.9601 - val_loss: 1.5113 - val_acc: 0.5882\n",
      "Epoch 7/7\n",
      "301/301 [==============================] - 16s 52ms/step - loss: 0.1212 - acc: 0.9734 - val_loss: 1.9379 - val_acc: 0.4706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f630a1556d8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint = ModelCheckpoint(filepath, monitor=\"loss\", verbose=1, save_best_only=True, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.000001)\n",
    "# print model.summary()\n",
    "model.fit(X_train, Y_train, batch_size=1, epochs=7, validation_split=0.1, shuffle=True, callbacks=[reduce_lr])\n",
    "# model.fit(X_train, Y_train, epochs = 7, batch_size=32, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3c142b42220e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvalidation_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvalidation_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "validation_size = 50\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = 128)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
